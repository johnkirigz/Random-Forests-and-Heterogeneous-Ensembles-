# Random-Forests-and-Heterogeneous-Ensembles
# Insurance and churn_modelling datasets
I loaded the insurance.csv and churn_modelling.csv dataset and investigated the variables' relationships. I preprocessed the data by dealing with missing values, encoding categorical variables, and dividing it into training and testing sets. After that, i trained and improved a Random Forest Regression model and tested its performance on the testing data set. Lastly, i trained and assessed a Heterogeneous Ensemble model on the testing set. For both models, the MSE was utilized as an evaluation statistic.
# FINDINGS 
# churn_modelling dataset
In the churn_modelling datasets, i got a Random Forest Mean Squared Error of 0.02 in training the models. This means that the predicted values from the random forest model have a low average squared difference from the actual values in the training dataset After combining models, the output of Random Forest Mean Squared Error: 0.11432525000000002. This value indicates how well the combined model is performing in predicting the target variable.

After evaluating the ensemble the output is Random Forest 1 Mean Squared Error: 0.11, Random Forest 2 Mean Squared Error: 0.11, Linear Regression Mean Squared Error: 0.14, Voting Regressor Mean Squared Error: 0.11 and Stacking Regressor Mean Squared Error: 0.11. This concludes that the results indicate that the ensemble method of combining different models produced a lower mean squared error than using any individual model alone.All of the random forest models and the voting regressor have roughly the same mean squared error, indicating that they perform similarly well.However, the linear regression model has a higher mean squared error, indicating that it does not predict the target variable as well as the other models. With the lowest mean squared error, the stacking regressor may be the best model for making predictions on this dataset.

In tuning the ensemble the output is Random Forest Mean Squared Error: 0.11432525000000002 and  Random Forest R-squared Score: 0.2759080422642034. This means the Random Forest model's mean squared error has decreased to 0.114, indicating that the model's performance has improved. The Random Forest model's R-squared score has also increased to 0.276, indicating that the model can explain 27.6% of the variance in the target variable. This indicates that tuning the ensemble has improved the Random Forest model's performance, making it a better predictor of the target variable.

# Insurance datasets
In the insurance datasets in training of data i got Random Forest Mean Squared Error: 20942520.922619622. A high mean squared error (MSE) value in the training phase of a random forest model indicates that the model is not fitting the data well.

In evaluating the ensemble the output is Random Forest 1 Mean Squared Error: 19597792.53, Random Forest 2 Mean Squared Error: 19624450.05, Linear Regression Mean Squared Error: 33596915.85, Voting Regressor Mean Squared Error: 20047686.89 and Stacking Regressor Mean Squared Error: 19565839.79. It appears that the Random Forest models have the lowest Mean Squared Error (MSE), indicating that they perform better in predicting the target variable than the Linear Regression and the ensemble methods (Voting Regressor and Stacking Regressor). Random Forest 1 and Random Forest 2 have similar MSE values, indicating that they predict the target variable equally well. 

In tuning the ensemble the output is Random Forest Mean Squared Error: 20942520.922619622 and Random Forest R-squared Score: 0.8651034329144947. A Random Forest Mean Squared Error of 20942520.922619622 indicates that the model is not predicting the target variable accurately. This indicates that the model is either overfitting or underfitting the data, or that the hyperparameters of the model need to be adjusted. According to the Random Forest R-squared Score of 0.8651034329144947, the model explains 86.51% of the variance in the target variable. This is a high R-squared score, indicating that the model is performing well
